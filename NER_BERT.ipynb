{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f409f28",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794ee93",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4b6649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ddds/anaconda3/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: transformers in /home/ddds/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: seqeval in /home/ddds/anaconda3/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: packaging in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pandas in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: filelock in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from seqeval) (1.2.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: spacy in /home/ddds/anaconda3/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: setuptools in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ddds/anaconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers seqeval\n",
    "!pip install spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2073b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6bc0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 00:13:21.861396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 00:13:21.928481: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 00:13:21.930751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-04 00:13:21.930756: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-04 00:13:21.941006: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-04 00:13:22.184067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 00:13:22.184095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 00:13:22.184098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-04-04 00:13:22.465803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-04 00:13:22.465821: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-04 00:13:22.465834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ddds-X670E-Pro-RS): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, ClassLabel, Sequence, load_dataset, load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import transformers\n",
    "from transformers import (AutoModelForTokenClassification,\n",
    "                          TFAutoModelForTokenClassification,\n",
    "                          AutoTokenizer, \n",
    "                          DataCollatorForTokenClassification,\n",
    "                          pipeline,\n",
    "                          TrainingArguments, \n",
    "                          Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf1703",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a94984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ade_corpus_v2 (/home/ddds/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_ade_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2a3e4c3712405196287963bb16b54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'indexes'],\n",
       "        num_rows: 6821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"ade_corpus_v2\", \"Ade_corpus_v2_drug_ade_relation\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ac466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c228952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplicate texts with different drug(s) and/or effect(s)\n",
    "# Consolidate to prevent model giving different labels for the same sentence.\n",
    "\n",
    "consolidated_dataset = {}\n",
    "\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"text\"] in consolidated_dataset:\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_start\"].update(row[\"indexes\"][\"drug\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_end\"].update(row[\"indexes\"][\"drug\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_start\"].update(row[\"indexes\"][\"effect\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_end\"].update(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug\"].append(row[\"drug\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect\"].append(row[\"effect\"])\n",
    "        \n",
    "    else:\n",
    "        consolidated_dataset[row[\"text\"]] = {\n",
    "            \"text\": row[\"text\"],\n",
    "            \"drug\": [row[\"drug\"]],\n",
    "            \"effect\": [row[\"effect\"]],\n",
    "            # use sets because the indices can repeat for various reasons\n",
    "            \"drug_indices_start\": set(row[\"indexes\"][\"drug\"][\"start_char\"]),\n",
    "            \"drug_indices_end\": set(row[\"indexes\"][\"drug\"][\"end_char\"]),\n",
    "            \"effect_indices_start\": set(row[\"indexes\"][\"effect\"][\"start_char\"]),\n",
    "            \"effect_indices_end\": set(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d415bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>{12}</td>\n",
       "      <td>{24}</td>\n",
       "      <td>{33}</td>\n",
       "      <td>{44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immobilization, while Paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>{91}</td>\n",
       "      <td>{109}</td>\n",
       "      <td>{143}</td>\n",
       "      <td>{168}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>{84}</td>\n",
       "      <td>{102}</td>\n",
       "      <td>{21}</td>\n",
       "      <td>{34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>{58, 71}</td>\n",
       "      <td>{80, 66}</td>\n",
       "      <td>{32}</td>\n",
       "      <td>{47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naproxen, the most common offender, has been a...</td>\n",
       "      <td>[Naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>{0}</td>\n",
       "      <td>{8}</td>\n",
       "      <td>{134}</td>\n",
       "      <td>{163}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      Intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  Immobilization, while Paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  Unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  METHODS: We report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  Naproxen, the most common offender, has been a...             [Naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               {12}             {24}   \n",
       "1         [increased calcium-release]               {91}            {109}   \n",
       "2                     [hypercalcemia]               {84}            {102}   \n",
       "3  [pseudoporphyria, pseudoporphyria]           {58, 71}         {80, 66}   \n",
       "4     [erythropoietic protoporphyria]                {0}              {8}   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \n",
       "0                 {33}               {44}  \n",
       "1                {143}              {168}  \n",
       "2                 {21}               {34}  \n",
       "3                 {32}               {47}  \n",
       "4                {134}              {163}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(consolidated_dataset.values()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b2cc078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since no spans overlap, we can sort to get 1:1 matched index spans\n",
    "# note that sets don't preserve insertion order\n",
    "\n",
    "df[\"drug_indices_start\"] = df[\"drug_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"drug_indices_end\"] = df[\"drug_indices_end\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_start\"] = df[\"effect_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_end\"] = df[\"effect_indices_end\"].apply(list).apply(sorted)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(str.lower)\n",
    "df[\"drug\"] = [[w.lower() for w in line] for line in df[\"drug\"]]\n",
    "df[\"effect\"] = [[w.lower() for w in line] for line in df[\"effect\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce3e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immobilization, while paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>[84]</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>methods: we report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>[58, 71]</td>\n",
       "      <td>[66, 80]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naproxen, the most common offender, has been a...</td>\n",
       "      <td>[naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[163]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  immobilization, while paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  methods: we report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  naproxen, the most common offender, has been a...             [naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               [12]             [24]   \n",
       "1         [increased calcium-release]               [91]            [109]   \n",
       "2                     [hypercalcemia]               [84]            [102]   \n",
       "3  [pseudoporphyria, pseudoporphyria]           [58, 71]         [66, 80]   \n",
       "4     [erythropoietic protoporphyria]                [0]              [8]   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \n",
       "0                 [33]               [44]  \n",
       "1                [143]              [168]  \n",
       "2                 [21]               [34]  \n",
       "3                 [32]               [47]  \n",
       "4                [134]              [163]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check string are lowercased\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "353478d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/ddds/.cache/huggingface/datasets/json/default-3c669057dd99a6d1/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e0f10f22544e4c962a3008701a1957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ead1e4df2114829a3d2df13d900937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/ddds/.cache/huggingface/datasets/json/default-3c669057dd99a6d1/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d285cf9b4fa43429c379398878be116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save to JSON to then import into Dataset object\n",
    "df.to_json(\"dataset.jsonl\", orient=\"records\", lines=True)\n",
    "cons_dataset = load_dataset(\"json\", data_files=\"dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b7ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "MAX_SEQUENCE_LENGTH = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb148e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIO Tagging\n",
    "\n",
    "label_list = ['O', 'B-DRUG', 'I-DRUG', 'B-EFFECT', 'I-EFFECT']\n",
    "\n",
    "def generate_row_labels(row, verbose=False):\n",
    "    \"\"\" Given a row from the consolidated `Ade_corpus_v2_drug_ade_relation` dataset, \n",
    "    generates BIO tags for drug and effect entities. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    labels = []\n",
    "    label = \"O\"\n",
    "    prefix = \"\"\n",
    "    \n",
    "    # while iterating through tokens, increment to traverse all drug and effect spans\n",
    "    drug_index = 0\n",
    "    effect_index = 0\n",
    "    \n",
    "    tokens = tokenizer(text, return_offsets_mapping=True, truncation=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    for n in range(len(tokens[\"input_ids\"])):\n",
    "        offset_start, offset_end = tokens[\"offset_mapping\"][n]\n",
    "\n",
    "        # should only happen for [CLS] and [SEP]\n",
    "        if offset_end - offset_start == 0:\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        \n",
    "        if drug_index < len(row[\"drug_indices_start\"]) and offset_start == row[\"drug_indices_start\"][drug_index]:\n",
    "            label = \"DRUG\"\n",
    "            prefix = \"B-\"\n",
    "\n",
    "        elif effect_index < len(row[\"effect_indices_start\"]) and offset_start == row[\"effect_indices_start\"][effect_index]:\n",
    "            label = \"EFFECT\"\n",
    "            prefix = \"B-\"\n",
    "        \n",
    "        labels.append(label_list.index(f\"{prefix}{label}\"))\n",
    "            \n",
    "        if drug_index < len(row[\"drug_indices_end\"]) and offset_end == row[\"drug_indices_end\"][drug_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            drug_index += 1\n",
    "            \n",
    "        elif effect_index < len(row[\"effect_indices_end\"]) and offset_end == row[\"effect_indices_end\"][effect_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            effect_index += 1\n",
    "\n",
    "        # need to transition \"inside\" if we just entered an entity\n",
    "        if prefix == \"B-\":\n",
    "            prefix = \"I-\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{row}\\n\")\n",
    "        orig = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"])\n",
    "        for n in range(len(labels)):\n",
    "            print(orig[n], labels[n])\n",
    "    tokens[\"labels\"] = labels\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf8f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'unaccountable severe hypercalcemia in a patient treated for hypoparathyroidism with dihydrotachysterol.', 'drug': ['dihydrotachysterol'], 'effect': ['hypercalcemia'], 'drug_indices_start': [84], 'drug_indices_end': [102], 'effect_indices_start': [21], 'effect_indices_end': [34]}\n",
      "\n",
      "[CLS] 0\n",
      "una 0\n",
      "##cco 0\n",
      "##unt 0\n",
      "##able 0\n",
      "severe 0\n",
      "hyper 3\n",
      "##cal 4\n",
      "##ce 4\n",
      "##mia 4\n",
      "in 0\n",
      "a 0\n",
      "patient 0\n",
      "treated 0\n",
      "for 0\n",
      "h 0\n",
      "##yp 0\n",
      "##opa 0\n",
      "##rath 0\n",
      "##yr 0\n",
      "##oid 0\n",
      "##ism 0\n",
      "with 0\n",
      "di 1\n",
      "##hy 2\n",
      "##dro 2\n",
      "##ta 2\n",
      "##chy 2\n",
      "##ster 2\n",
      "##ol 2\n",
      ". 0\n",
      "[SEP] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 14477, 21408, 16671, 3085, 5729, 23760, 9289, 3401, 10092, 1999, 1037, 5776, 5845, 2005, 1044, 22571, 29477, 27362, 12541, 9314, 2964, 2007, 4487, 10536, 22196, 2696, 11714, 6238, 4747, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [(0, 0), (0, 3), (3, 6), (6, 9), (9, 13), (14, 20), (21, 26), (26, 29), (29, 31), (31, 34), (35, 37), (38, 39), (40, 47), (48, 55), (56, 59), (60, 61), (61, 63), (63, 66), (66, 70), (70, 72), (72, 75), (75, 78), (79, 83), (84, 86), (86, 88), (88, 91), (91, 93), (93, 96), (96, 100), (100, 102), (102, 103), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], 'labels': [0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the ouput\n",
    "\n",
    "generate_row_labels(cons_dataset[\"train\"][2], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc630f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'drug_indices_start', 'drug_indices_end', 'effect_indices_start', 'effect_indices_end', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n",
       "        num_rows: 4271\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset = cons_dataset.map(generate_row_labels)\n",
    "labeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "441b2b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>offset_mapping</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>[101, 26721, 8159, 3560, 17207, 8939, 21716, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 5], [5, 8], [8, 11], [12, 14], [1...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 3, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immobilization, while paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[168]</td>\n",
       "      <td>[101, 10047, 5302, 14454, 3989, 1010, 2096, 39...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 2], [2, 4], [4, 7], [7, 14], [14,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>[84]</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[101, 14477, 21408, 16671, 3085, 5729, 23760, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 6], [6, 9], [9, 13], [14,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>methods: we report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>[58, 71]</td>\n",
       "      <td>[66, 80]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[101, 4725, 1024, 2057, 3189, 2048, 3572, 1997...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 7], [7, 8], [9, 11], [12, 18], [1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naproxen, the most common offender, has been a...</td>\n",
       "      <td>[naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[163]</td>\n",
       "      <td>[101, 18996, 3217, 2595, 2368, 1010, 1996, 208...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 5], [5, 6], [6, 8], [8, 9...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  immobilization, while paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  methods: we report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  naproxen, the most common offender, has been a...             [naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               [12]             [24]   \n",
       "1         [increased calcium-release]               [91]            [109]   \n",
       "2                     [hypercalcemia]               [84]            [102]   \n",
       "3  [pseudoporphyria, pseudoporphyria]           [58, 71]         [66, 80]   \n",
       "4     [erythropoietic protoporphyria]                [0]              [8]   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \\\n",
       "0                 [33]               [44]   \n",
       "1                [143]              [168]   \n",
       "2                 [21]               [34]   \n",
       "3                 [32]               [47]   \n",
       "4                [134]              [163]   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 26721, 8159, 3560, 17207, 8939, 21716, 2...   \n",
       "1  [101, 10047, 5302, 14454, 3989, 1010, 2096, 39...   \n",
       "2  [101, 14477, 21408, 16671, 3085, 5729, 23760, ...   \n",
       "3  [101, 4725, 1024, 2057, 3189, 2048, 3572, 1997...   \n",
       "4  [101, 18996, 3217, 2595, 2368, 1010, 1996, 208...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      offset_mapping  \\\n",
       "0  [[0, 0], [0, 5], [5, 8], [8, 11], [12, 14], [1...   \n",
       "1  [[0, 0], [0, 2], [2, 4], [4, 7], [7, 14], [14,...   \n",
       "2  [[0, 0], [0, 3], [3, 6], [6, 9], [9, 13], [14,...   \n",
       "3  [[0, 0], [0, 7], [7, 8], [9, 11], [12, 18], [1...   \n",
       "4  [[0, 0], [0, 3], [3, 5], [5, 6], [6, 8], [8, 9...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 3, 4, 4, 4, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 1, ...  \n",
       "4  [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What columns does the dataframe have?\n",
    "\n",
    "df = labeled_dataset['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a04f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
    "                            [int(.8 * len(df)), int(.9 * len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aff05c",
   "metadata": {},
   "source": [
    "# Classification with BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bebe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 00:13:27.205815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c6d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output Data\n",
    "\n",
    "# Train Data\n",
    "train_txt =  df_train['text'].values.tolist()\n",
    "train_encodings = tokenizer(train_txt,\n",
    "                            padding='max_length', \n",
    "                            max_length = MAX_SEQUENCE_LENGTH, \n",
    "                            truncation=True, \n",
    "                            return_tensors=\"tf\") \n",
    "train_labels = list(df_train['labels'])\n",
    "\n",
    "\n",
    "# Validation Data\n",
    "val_txt =  df_val['text'].values.tolist()\n",
    "val_encodings = tokenizer(val_txt,\n",
    "                          padding='max_length', \n",
    "                          max_length = MAX_SEQUENCE_LENGTH, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"tf\")\n",
    "val_labels = list(df_val['labels'])\n",
    "\n",
    "# Test Data\n",
    "test_txt =  df_test['text'].values.tolist()\n",
    "test_encodings = tokenizer(test_txt,\n",
    "                           padding='max_length', \n",
    "                           max_length = MAX_SEQUENCE_LENGTH, \n",
    "                           truncation=True, \n",
    "                           return_tensors=\"tf\")\n",
    "test_labels = list(df_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf5a52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_cls_model(max_sequence_length=119,\n",
    "                          hidden_size = 200, \n",
    "                          num_classes = 5,\n",
    "                          dropout=0.05,\n",
    "                          learning_rate=0.00001):\n",
    "\n",
    "    model.trainable=True    \n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}\n",
    "\n",
    "    bert_out = model(bert_inputs)\n",
    "\n",
    "    cls_token = bert_out[0]\n",
    "\n",
    "    last_hidden_output = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
    "    last_hidden_output = tf.keras.layers.Dropout(dropout)(last_hidden_output)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(num_classes, activation='softmax',name='classification_layer')(last_hidden_output)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "\n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                               metrics='sparse_categorical_accuracy')\n",
    "\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74442d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = create_bert_cls_model(num_classes=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df8c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 119)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 119)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 119)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_for_token_classificati  TFTokenClassifierOu  108895493  ['attention_mask_layer[0][0]',   \n",
      " on (TFBertForTokenClassificati  tput(loss=None, log              'input_ids_layer[0][0]',        \n",
      " on)                            its=(None, 119, 5),               'token_type_ids_layer[0][0]']   \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 119, 200)     1200        ['tf_bert_for_token_classificatio\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 119, 200)     0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 119, 5)       1005        ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,897,698\n",
      "Trainable params: 108,897,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837db4a",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63432b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "214/214 [==============================] - 228s 1s/step - loss: 0.5583 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.3434 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 219s 1s/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9199 - val_loss: 0.1829 - val_sparse_categorical_accuracy: 0.9293\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 221s 1s/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9652\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 221s 1s/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9836\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 221s 1s/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0746 - val_sparse_categorical_accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75d06769b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_history = bert_model.fit([train_encodings.input_ids,\n",
    "                                     train_encodings.token_type_ids, \n",
    "                                     train_encodings.attention_mask], \n",
    "                                    np.array(train_labels),   \n",
    "                                    validation_data=(\n",
    "                                        [val_encodings.input_ids,\n",
    "                                         val_encodings.token_type_ids, \n",
    "                                         val_encodings.attention_mask], \n",
    "                                    np.array(val_labels)),    \n",
    "                                    batch_size=16, \n",
    "                                    epochs=5\n",
    "                                   )\n",
    "\n",
    "bert_model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d354a0",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48b67b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 545ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9829\n",
      "Test loss 0.07577356696128845\n",
      "Test accuracy 0.9829380512237549\n"
     ]
    }
   ],
   "source": [
    "bert_score = bert_model.evaluate([test_encodings.input_ids, test_encodings.token_type_ids, test_encodings.attention_mask], \n",
    "                                 np.array(test_labels))\n",
    "\n",
    "print('Test loss', bert_score[0])\n",
    "print('Test accuracy', bert_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d8478",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd483270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 9s 544ms/step\n"
     ]
    }
   ],
   "source": [
    "bert_predictions = bert_model.predict([test_encodings.input_ids[:], test_encodings.token_type_ids[:], test_encodings.attention_mask[:]])\n",
    "bert_predictions = tf.argmax(bert_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8df759cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 119), dtype=int64, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 0, 1, 2, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2,\n",
       "        0, 0, 3, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 1, 2, 2,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_predictions[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0e485",
   "metadata": {},
   "source": [
    "# Metric (Precision, Recall, and F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abbbfa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7419/1661156271.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 544ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DRUG': {'precision': 0.8880994671403197,\n",
       "  'recall': 0.9433962264150944,\n",
       "  'f1': 0.9149130832570905,\n",
       "  'number': 530},\n",
       " 'EFFECT': {'precision': 0.6524216524216524,\n",
       "  'recall': 0.8403669724770643,\n",
       "  'f1': 0.7345629510825982,\n",
       "  'number': 545},\n",
       " 'overall_precision': 0.7573122529644268,\n",
       " 'overall_recall': 0.8911627906976745,\n",
       " 'overall_f1': 0.8188034188034187,\n",
       " 'overall_accuracy': 0.982938035027095}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "bert_predictions = bert_model.predict([test_encodings.input_ids[:], test_encodings.token_type_ids[:], test_encodings.attention_mask[:]])\n",
    "predictions = np.argmax(bert_predictions, axis=2)\n",
    "labels = np.array(test_labels)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a7dc20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'B-EFFECT', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Print out some predictions and compare to labels\n",
    "\n",
    "print(true_predictions[0])\n",
    "print(true_predictions[1])\n",
    "print(true_predictions[2])\n",
    "print(true_predictions[3])\n",
    "print(true_predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3370a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'I-DRUG', 'O', 'O', 'B-EFFECT', 'O', 'O', 'O', 'O', 'B-EFFECT', 'I-EFFECT', 'I-EFFECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Print out some labels and compare to predictions\n",
    "\n",
    "print(true_labels[0])\n",
    "print(true_labels[1])\n",
    "print(true_labels[2])\n",
    "print(true_labels[3])\n",
    "print(true_labels[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
