{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f409f28",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794ee93",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4b6649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ddds/anaconda3/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: transformers in /home/ddds/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: seqeval in /home/ddds/anaconda3/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: aiohttp in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: xxhash in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: pandas in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: filelock in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from seqeval) (1.2.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: spacy in /home/ddds/anaconda3/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /home/ddds/anaconda3/lib/python3.10/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ddds/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ddds/anaconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ddds/anaconda3/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ddds/anaconda3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers seqeval\n",
    "!pip install spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2073b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6bc0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 02:08:19.207973: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 02:08:19.208866: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-04 02:08:19.226363: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-04 02:08:19.226783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 02:08:19.574708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, ClassLabel, Sequence, load_dataset, load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import transformers\n",
    "from transformers import (AutoModelForTokenClassification,\n",
    "                          TFAutoModelForTokenClassification,\n",
    "                          AutoTokenizer, \n",
    "                          DataCollatorForTokenClassification,\n",
    "                          pipeline,\n",
    "                          TrainingArguments, \n",
    "                          Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf1703",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a94984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ade_corpus_v2 (/home/ddds/.cache/huggingface/datasets/ade_corpus_v2/Ade_corpus_v2_drug_ade_relation/1.0.0/940d61334dbfac6b01ac5d00286a2122608b8dc79706ee7e9206a1edb172c559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a94450f6d147ccb9f6144c23b79542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'indexes'],\n",
       "        num_rows: 6821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"ade_corpus_v2\", \"Ade_corpus_v2_drug_ade_relation\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ac466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Intravenous azithromycin-induced ototoxicity.',\n",
       " 'drug': 'azithromycin',\n",
       " 'effect': 'ototoxicity',\n",
       " 'indexes': {'drug': {'start_char': [12], 'end_char': [24]},\n",
       "  'effect': {'start_char': [33], 'end_char': [44]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c228952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplicate texts with different drug(s) and/or effect(s)\n",
    "# Consolidate to prevent model giving different labels for the same sentence.\n",
    "\n",
    "consolidated_dataset = {}\n",
    "\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"text\"] in consolidated_dataset:\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_start\"].update(row[\"indexes\"][\"drug\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug_indices_end\"].update(row[\"indexes\"][\"drug\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_start\"].update(row[\"indexes\"][\"effect\"][\"start_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect_indices_end\"].update(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"drug\"].append(row[\"drug\"])\n",
    "        consolidated_dataset[row[\"text\"]][\"effect\"].append(row[\"effect\"])\n",
    "        \n",
    "    else:\n",
    "        consolidated_dataset[row[\"text\"]] = {\n",
    "            \"text\": row[\"text\"],\n",
    "            \"drug\": [row[\"drug\"]],\n",
    "            \"effect\": [row[\"effect\"]],\n",
    "            # use sets because the indices can repeat for various reasons\n",
    "            \"drug_indices_start\": set(row[\"indexes\"][\"drug\"][\"start_char\"]),\n",
    "            \"drug_indices_end\": set(row[\"indexes\"][\"drug\"][\"end_char\"]),\n",
    "            \"effect_indices_start\": set(row[\"indexes\"][\"effect\"][\"start_char\"]),\n",
    "            \"effect_indices_end\": set(row[\"indexes\"][\"effect\"][\"end_char\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d415bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>{12}</td>\n",
       "      <td>{24}</td>\n",
       "      <td>{33}</td>\n",
       "      <td>{44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immobilization, while Paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>{91}</td>\n",
       "      <td>{109}</td>\n",
       "      <td>{143}</td>\n",
       "      <td>{168}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>{84}</td>\n",
       "      <td>{102}</td>\n",
       "      <td>{21}</td>\n",
       "      <td>{34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>{58, 71}</td>\n",
       "      <td>{80, 66}</td>\n",
       "      <td>{32}</td>\n",
       "      <td>{47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naproxen, the most common offender, has been a...</td>\n",
       "      <td>[Naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>{0}</td>\n",
       "      <td>{8}</td>\n",
       "      <td>{134}</td>\n",
       "      <td>{163}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      Intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  Immobilization, while Paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  Unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  METHODS: We report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  Naproxen, the most common offender, has been a...             [Naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               {12}             {24}   \n",
       "1         [increased calcium-release]               {91}            {109}   \n",
       "2                     [hypercalcemia]               {84}            {102}   \n",
       "3  [pseudoporphyria, pseudoporphyria]           {58, 71}         {80, 66}   \n",
       "4     [erythropoietic protoporphyria]                {0}              {8}   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \n",
       "0                 {33}               {44}  \n",
       "1                {143}              {168}  \n",
       "2                 {21}               {34}  \n",
       "3                 {32}               {47}  \n",
       "4                {134}              {163}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(consolidated_dataset.values()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b2cc078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since no spans overlap, we can sort to get 1:1 matched index spans\n",
    "# note that sets don't preserve insertion order\n",
    "\n",
    "df[\"drug_indices_start\"] = df[\"drug_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"drug_indices_end\"] = df[\"drug_indices_end\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_start\"] = df[\"effect_indices_start\"].apply(list).apply(sorted)\n",
    "df[\"effect_indices_end\"] = df[\"effect_indices_end\"].apply(list).apply(sorted)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(str.lower)\n",
    "df[\"drug\"] = [[w.lower() for w in line] for line in df[\"drug\"]]\n",
    "df[\"effect\"] = [[w.lower() for w in line] for line in df[\"effect\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce3e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immobilization, while paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>[84]</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>methods: we report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>[58, 71]</td>\n",
       "      <td>[66, 80]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naproxen, the most common offender, has been a...</td>\n",
       "      <td>[naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[163]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  immobilization, while paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  methods: we report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  naproxen, the most common offender, has been a...             [naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               [12]             [24]   \n",
       "1         [increased calcium-release]               [91]            [109]   \n",
       "2                     [hypercalcemia]               [84]            [102]   \n",
       "3  [pseudoporphyria, pseudoporphyria]           [58, 71]         [66, 80]   \n",
       "4     [erythropoietic protoporphyria]                [0]              [8]   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \n",
       "0                 [33]               [44]  \n",
       "1                [143]              [168]  \n",
       "2                 [21]               [34]  \n",
       "3                 [32]               [47]  \n",
       "4                [134]              [163]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check string are lowercased\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "353478d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/ddds/.cache/huggingface/datasets/json/default-d230646c5a883978/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b5c9323f574e1d8dc1059d0d1ab2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53bf32032214fa3baa0523a677cb610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/ddds/.cache/huggingface/datasets/json/default-d230646c5a883978/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6440f817ffb44d97b844129a35d77d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save to JSON to then import into Dataset object\n",
    "df.to_json(\"dataset.jsonl\", orient=\"records\", lines=True)\n",
    "cons_dataset = load_dataset(\"json\", data_files=\"dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b7ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"allenai/scibert_scivocab_uncased\"\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "MAX_SEQUENCE_LENGTH = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb148e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIO Tagging\n",
    "\n",
    "label_list = ['O', 'B-DRUG', 'I-DRUG', 'B-EFFECT', 'I-EFFECT']\n",
    "\n",
    "def generate_row_labels(row, verbose=False):\n",
    "    \"\"\" Given a row from the consolidated `Ade_corpus_v2_drug_ade_relation` dataset, \n",
    "    generates BIO tags for drug and effect entities. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    labels = []\n",
    "    label = \"O\"\n",
    "    prefix = \"\"\n",
    "    \n",
    "    # while iterating through tokens, increment to traverse all drug and effect spans\n",
    "    drug_index = 0\n",
    "    effect_index = 0\n",
    "    \n",
    "    tokens = tokenizer(text, return_offsets_mapping=True, truncation=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    for n in range(len(tokens[\"input_ids\"])):\n",
    "        offset_start, offset_end = tokens[\"offset_mapping\"][n]\n",
    "\n",
    "        # should only happen for [CLS] and [SEP]\n",
    "        if offset_end - offset_start == 0:\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        \n",
    "        if drug_index < len(row[\"drug_indices_start\"]) and offset_start == row[\"drug_indices_start\"][drug_index]:\n",
    "            label = \"DRUG\"\n",
    "            prefix = \"B-\"\n",
    "\n",
    "        elif effect_index < len(row[\"effect_indices_start\"]) and offset_start == row[\"effect_indices_start\"][effect_index]:\n",
    "            label = \"EFFECT\"\n",
    "            prefix = \"B-\"\n",
    "        \n",
    "        labels.append(label_list.index(f\"{prefix}{label}\"))\n",
    "            \n",
    "        if drug_index < len(row[\"drug_indices_end\"]) and offset_end == row[\"drug_indices_end\"][drug_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            drug_index += 1\n",
    "            \n",
    "        elif effect_index < len(row[\"effect_indices_end\"]) and offset_end == row[\"effect_indices_end\"][effect_index]:\n",
    "            label = \"O\"\n",
    "            prefix = \"\"\n",
    "            effect_index += 1\n",
    "\n",
    "        # need to transition \"inside\" if we just entered an entity\n",
    "        if prefix == \"B-\":\n",
    "            prefix = \"I-\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{row}\\n\")\n",
    "        orig = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"])\n",
    "        for n in range(len(labels)):\n",
    "            print(orig[n], labels[n])\n",
    "    tokens[\"labels\"] = labels\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf8f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'unaccountable severe hypercalcemia in a patient treated for hypoparathyroidism with dihydrotachysterol.', 'drug': ['dihydrotachysterol'], 'effect': ['hypercalcemia'], 'drug_indices_start': [84], 'drug_indices_end': [102], 'effect_indices_start': [21], 'effect_indices_end': [34]}\n",
      "\n",
      "[CLS] 0\n",
      "una 0\n",
      "##cc 0\n",
      "##ount 0\n",
      "##able 0\n",
      "severe 0\n",
      "hyper 3\n",
      "##calc 4\n",
      "##emia 4\n",
      "in 0\n",
      "a 0\n",
      "patient 0\n",
      "treated 0\n",
      "for 0\n",
      "hypo 0\n",
      "##par 0\n",
      "##athy 0\n",
      "##roid 0\n",
      "##ism 0\n",
      "with 0\n",
      "dihydro 1\n",
      "##tac 2\n",
      "##hy 2\n",
      "##ster 2\n",
      "##ol 2\n",
      ". 0\n",
      "[SEP] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n",
      "[PAD] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 10313, 742, 1464, 318, 3167, 1884, 13208, 3788, 121, 106, 1454, 2338, 168, 19877, 961, 16937, 4441, 960, 190, 26860, 29036, 1844, 5591, 162, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [(0, 0), (0, 3), (3, 5), (5, 9), (9, 13), (14, 20), (21, 26), (26, 30), (30, 34), (35, 37), (38, 39), (40, 47), (48, 55), (56, 59), (60, 64), (64, 67), (67, 71), (71, 75), (75, 78), (79, 83), (84, 91), (91, 94), (94, 96), (96, 100), (100, 102), (102, 103), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], 'labels': [0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the ouput\n",
    "\n",
    "generate_row_labels(cons_dataset[\"train\"][2], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc630f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'drug', 'effect', 'drug_indices_start', 'drug_indices_end', 'effect_indices_start', 'effect_indices_end', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n",
       "        num_rows: 4271\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset = cons_dataset.map(generate_row_labels)\n",
    "labeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "441b2b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>effect</th>\n",
       "      <th>drug_indices_start</th>\n",
       "      <th>drug_indices_end</th>\n",
       "      <th>effect_indices_start</th>\n",
       "      <th>effect_indices_end</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>offset_mapping</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intravenous azithromycin-induced ototoxicity.</td>\n",
       "      <td>[azithromycin]</td>\n",
       "      <td>[ototoxicity]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[44]</td>\n",
       "      <td>[102, 9912, 5593, 180, 16372, 579, 2651, 5381,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0], [0, 11], [12, 14], [14, 17], [17, 24]...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immobilization, while paget's bone disease was...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[increased calcium-release]</td>\n",
       "      <td>[91]</td>\n",
       "      <td>[109]</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[168]</td>\n",
       "      <td>[102, 21028, 422, 969, 3707, 30108, 2505, 112,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 14], [14, 15], [16, 21], [22, 26]...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unaccountable severe hypercalcemia in a patien...</td>\n",
       "      <td>[dihydrotachysterol]</td>\n",
       "      <td>[hypercalcemia]</td>\n",
       "      <td>[84]</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[102, 10313, 742, 1464, 318, 3167, 1884, 13208...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 5], [5, 9], [9, 13], [14,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>methods: we report two cases of pseudoporphyri...</td>\n",
       "      <td>[naproxen, oxaprozin]</td>\n",
       "      <td>[pseudoporphyria, pseudoporphyria]</td>\n",
       "      <td>[58, 71]</td>\n",
       "      <td>[66, 80]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[47]</td>\n",
       "      <td>[102, 1045, 862, 185, 2024, 502, 1299, 131, 89...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 7], [7, 8], [9, 11], [12, 18], [1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naproxen, the most common offender, has been a...</td>\n",
       "      <td>[naproxen]</td>\n",
       "      <td>[erythropoietic protoporphyria]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[163]</td>\n",
       "      <td>[102, 15584, 12848, 117, 422, 111, 755, 1495, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0], [0, 3], [3, 6], [6, 8], [8, 9], [10, ...</td>\n",
       "      <td>[0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   drug  \\\n",
       "0      intravenous azithromycin-induced ototoxicity.         [azithromycin]   \n",
       "1  immobilization, while paget's bone disease was...   [dihydrotachysterol]   \n",
       "2  unaccountable severe hypercalcemia in a patien...   [dihydrotachysterol]   \n",
       "3  methods: we report two cases of pseudoporphyri...  [naproxen, oxaprozin]   \n",
       "4  naproxen, the most common offender, has been a...             [naproxen]   \n",
       "\n",
       "                               effect drug_indices_start drug_indices_end  \\\n",
       "0                       [ototoxicity]               [12]             [24]   \n",
       "1         [increased calcium-release]               [91]            [109]   \n",
       "2                     [hypercalcemia]               [84]            [102]   \n",
       "3  [pseudoporphyria, pseudoporphyria]           [58, 71]         [66, 80]   \n",
       "4     [erythropoietic protoporphyria]                [0]              [8]   \n",
       "\n",
       "  effect_indices_start effect_indices_end  \\\n",
       "0                 [33]               [44]   \n",
       "1                [143]              [168]   \n",
       "2                 [21]               [34]   \n",
       "3                 [32]               [47]   \n",
       "4                [134]              [163]   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [102, 9912, 5593, 180, 16372, 579, 2651, 5381,...   \n",
       "1  [102, 21028, 422, 969, 3707, 30108, 2505, 112,...   \n",
       "2  [102, 10313, 742, 1464, 318, 3167, 1884, 13208...   \n",
       "3  [102, 1045, 862, 185, 2024, 502, 1299, 131, 89...   \n",
       "4  [102, 15584, 12848, 117, 422, 111, 755, 1495, ...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      offset_mapping  \\\n",
       "0  [[0, 0], [0, 11], [12, 14], [14, 17], [17, 24]...   \n",
       "1  [[0, 0], [0, 14], [14, 15], [16, 21], [22, 26]...   \n",
       "2  [[0, 0], [0, 3], [3, 5], [5, 9], [9, 13], [14,...   \n",
       "3  [[0, 0], [0, 7], [7, 8], [9, 11], [12, 18], [1...   \n",
       "4  [[0, 0], [0, 3], [3, 6], [6, 8], [8, 9], [10, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 1, ...  \n",
       "4  [0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What columns does the dataframe have?\n",
    "\n",
    "df = labeled_dataset['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a04f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
    "                            [int(.8 * len(df)), int(.9 * len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aff05c",
   "metadata": {},
   "source": [
    "# Classification with SciBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11bebe31",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'keras.saving.hdf5_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py:1076\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:38\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     29\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     TFTokenClassifierOutput,\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[1;32m     40\u001b[0m     TFMaskedLanguageModelingLoss,\n\u001b[1;32m     41\u001b[0m     TFModelInputType,\n\u001b[1;32m     42\u001b[0m     TFMultipleChoiceLoss,\n\u001b[1;32m     43\u001b[0m     TFNextSentencePredictionLoss,\n\u001b[1;32m     44\u001b[0m     TFPreTrainedModel,\n\u001b[1;32m     45\u001b[0m     TFQuestionAnsweringLoss,\n\u001b[1;32m     46\u001b[0m     TFSequenceClassificationLoss,\n\u001b[1;32m     47\u001b[0m     TFTokenClassificationLoss,\n\u001b[1;32m     48\u001b[0m     get_initializer,\n\u001b[1;32m     49\u001b[0m     keras_serializable,\n\u001b[1;32m     50\u001b[0m     unpack_inputs,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shape_list, stable_softmax\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:39\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Repository, list_repo_files\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhdf5_format\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_attributes_to_hdf5_group\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_file_size_to_int, get_checkpoint_shard_files\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.saving.hdf5_format'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModelForTokenClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:462\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    459\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 462\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    464\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:359\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 359\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:590\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    589\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:604\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:553\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py:1066\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1066\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py:1078\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1079\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1081\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nNo module named 'keras.saving.hdf5_format'"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output Data\n",
    "\n",
    "# Train Data\n",
    "train_txt =  df_train['text'].values.tolist()\n",
    "train_encodings = tokenizer(train_txt,\n",
    "                            padding='max_length', \n",
    "                            max_length = MAX_SEQUENCE_LENGTH, \n",
    "                            truncation=True, \n",
    "                            return_tensors=\"tf\") \n",
    "train_labels = list(df_train['labels'])\n",
    "\n",
    "\n",
    "# Validation Data\n",
    "val_txt =  df_val['text'].values.tolist()\n",
    "val_encodings = tokenizer(val_txt,\n",
    "                          padding='max_length', \n",
    "                          max_length = MAX_SEQUENCE_LENGTH, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"tf\")\n",
    "val_labels = list(df_val['labels'])\n",
    "\n",
    "# Test Data\n",
    "test_txt =  df_test['text'].values.tolist()\n",
    "test_encodings = tokenizer(test_txt,\n",
    "                           padding='max_length', \n",
    "                           max_length = MAX_SEQUENCE_LENGTH, \n",
    "                           truncation=True, \n",
    "                           return_tensors=\"tf\")\n",
    "test_labels = list(df_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scibert_cls_model(max_sequence_length=119,\n",
    "                          hidden_size = 200, \n",
    "                          num_classes = 5,\n",
    "                          dropout=0.05,\n",
    "                          learning_rate=0.00001):\n",
    "\n",
    "    model.trainable=True    \n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    scibert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}\n",
    "\n",
    "    scibert_out = model(scibert_inputs)\n",
    "\n",
    "    cls_token = scibert_out[0]\n",
    "\n",
    "    last_hidden_output = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
    "    last_hidden_output = tf.keras.layers.Dropout(dropout)(last_hidden_output)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(num_classes, activation='softmax',name='classification_layer')(last_hidden_output)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "\n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                               metrics='sparse_categorical_accuracy')\n",
    "\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74442d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_model = create_scibert_cls_model(num_classes=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837db4a",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63432b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_model_history = scibert_model.fit([train_encodings.input_ids,\n",
    "                                           train_encodings.token_type_ids, \n",
    "                                           train_encodings.attention_mask], \n",
    "                                          np.array(train_labels),\n",
    "                                          validation_data=([val_encodings.input_ids,\n",
    "                                                            val_encodings.token_type_ids, \n",
    "                                                            val_encodings.attention_mask], \n",
    "                                                           np.array(val_labels)),    \n",
    "                                          batch_size=16,\n",
    "                                          epochs=5\n",
    "                                         )\n",
    "\n",
    "scibert_model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d354a0",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b67b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_score = scibert_model.evaluate([test_encodings.input_ids, \n",
    "                                        test_encodings.token_type_ids, \n",
    "                                        test_encodings.attention_mask], \n",
    "                                       np.array(test_labels))\n",
    "\n",
    "print('Test loss', scibert_score[0])\n",
    "print('Test accuracy', scibert_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d8478",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd483270",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_predictions = scibert_model.predict([test_encodings.input_ids[:], \n",
    "                                             test_encodings.token_type_ids[:], \n",
    "                                             test_encodings.attention_mask[:]])\n",
    "scibert_predictions = tf.argmax(scibert_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df759cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_predictions[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0e485",
   "metadata": {},
   "source": [
    "# Metric (Precision, Recall, and F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbfa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "scibert_predictions = scibert_model.predict([test_encodings.input_ids[:], \n",
    "                                             test_encodings.token_type_ids[:], \n",
    "                                             test_encodings.attention_mask[:]])\n",
    "predictions = np.argmax(scibert_predictions, axis=2)\n",
    "labels = np.array(test_labels)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some predictions and compare to labels\n",
    "\n",
    "print(true_predictions[0])\n",
    "print(true_predictions[1])\n",
    "print(true_predictions[2])\n",
    "print(true_predictions[3])\n",
    "print(true_predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3370a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some labels and compare to predictions\n",
    "\n",
    "print(true_labels[0])\n",
    "print(true_labels[1])\n",
    "print(true_labels[2])\n",
    "print(true_labels[3])\n",
    "print(true_labels[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
